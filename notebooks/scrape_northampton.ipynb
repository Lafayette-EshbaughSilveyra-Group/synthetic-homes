{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install requests selenium",
   "id": "89c3bfa9ea392afb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ],
   "id": "ee5fed9dfb1cea3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-27T19:29:40.839850Z",
     "start_time": "2025-06-27T19:29:40.768279Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def init_driver(headless=False):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "def click_tab(driver, tab_text):\n",
    "    tabs = driver.find_elements(By.XPATH, f\"//a[span[contains(text(), '{tab_text}')]]\")\n",
    "    for tab in tabs:\n",
    "        if tab.is_displayed():\n",
    "            tab.click()\n",
    "            time.sleep(2)\n",
    "            return\n",
    "    print(f\"[WARN] Tab with text '{tab_text}' not found.\")\n",
    "\n",
    "def scrape_residential_tab(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, \"Residential\")))\n",
    "    except:\n",
    "        print(\"[WARN] Residential table not found.\")\n",
    "        return {}\n",
    "\n",
    "    data = {}\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"#Residential tr\")\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cells) >= 2:\n",
    "            key = cells[0].text.strip().replace(\":\", \"\")\n",
    "            value = cells[1].text.strip()\n",
    "            if key:\n",
    "                data[key] = value\n",
    "    return data\n",
    "\n",
    "def wait_for_photoDetails(driver, timeout=10):\n",
    "    for _ in range(timeout * 10):\n",
    "        try:\n",
    "            result = driver.execute_script(\"return typeof photoDetails !== 'undefined' && photoDetails.length > 0\")\n",
    "            if result:\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(0.1)\n",
    "    return False\n",
    "\n",
    "def scrape_and_download_photos_from_photoDetails(driver, address_folder):\n",
    "    if not wait_for_photoDetails(driver):\n",
    "        print(\"[WARN] photoDetails not found or empty.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        photo_details_json = driver.execute_script(\"return JSON.stringify(photoDetails);\")\n",
    "        photo_details = json.loads(photo_details_json)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Couldn't extract photoDetails: {e}\")\n",
    "        return []\n",
    "\n",
    "    photo_urls = []\n",
    "    for idx, photo in enumerate(photo_details):\n",
    "        std_url = f\"https://www.ncpub.org/_web/api/document/{photo['Id']}/standard?token=RnNBOFBQNFhzakRDS3dzVVFPYm1wVHpMMFhZR2FvVGZSWEFmRkc5SDE0az0=\"\n",
    "        photo_urls.append(std_url)\n",
    "        try:\n",
    "            img_data = requests.get(std_url).content\n",
    "            with open(os.path.join(address_folder, f\"photo_{idx+1}.jpg\"), 'wb') as f:\n",
    "                f.write(img_data)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to download image {idx+1}: {e}\")\n",
    "    return photo_urls\n",
    "\n",
    "def get_total_record_count(driver):\n",
    "    try:\n",
    "        txt = driver.find_element(By.ID, \"DTLNavigator_txtFromTo\").get_attribute(\"value\")\n",
    "        return int(txt.split(\" of \")[-1])\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def scrape_sketch_details(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the table with class 'rgMasterTable' inside div.rgDataDiv and returns a dictionary\n",
    "    mapping the third <td>'s text to the integer value of the fourth <td> in each row.\n",
    "    \n",
    "    Args:\n",
    "        driver: Selenium WebDriver object, assumed to be on the target page.\n",
    "    \n",
    "    Returns:\n",
    "        dict: { third_td_text: int(fourth_td_text) }\n",
    "    \"\"\"\n",
    "    details = {}\n",
    "    \n",
    "    iframe = driver.find_element(By.TAG_NAME, \"iframe\")\n",
    "    driver.switch_to.frame(iframe)\n",
    "    \n",
    "    # Wait for the table inside div.rgDataDiv to load\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.rgDataDiv table.rgMasterTable\"))\n",
    "    )\n",
    "\n",
    "    table = driver.find_element(By.CSS_SELECTOR, \"div#RadGrid1_GridData table\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    \n",
    "    print(f\"[INFO] {len(rows)} rows found.\")\n",
    "\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(tds) >= 4:\n",
    "            key = tds[2].text.strip()\n",
    "            value_text = tds[3].text.strip()\n",
    "            try:\n",
    "                value = int(value_text.replace(',', ''))  # Remove commas if numbers are formatted\n",
    "                details[key] = value\n",
    "            except ValueError:\n",
    "                continue  # Skip rows where the fourth td is not an integer\n",
    "\n",
    "    return details\n",
    "\n",
    "def scrape_sketch_image(driver, address_folder):\n",
    "    \"\"\"\n",
    "    Takes a screenshot of the sketch image (with overlays rendered) and saves it to address_folder.\n",
    "    \n",
    "    Args:\n",
    "        driver: Selenium WebDriver object, assumed to be on the target page.\n",
    "        address_folder: str, path to save the screenshot.\n",
    "    \"\"\"\n",
    "    # Wait for image to load (max 10 seconds)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"BinImage\"))\n",
    "    )\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    element = driver.find_element(By.ID, \"BinImage\")\n",
    "    element.screenshot(f\"{address_folder}/sketch.png\")\n",
    "    driver.switch_to.default_content()\n",
    "    \n",
    "\n",
    "def scrape_all_records_on_street(driver, street_name, output_dir):\n",
    "    base_url = \"https://www.ncpub.org/_web/search/commonsearch.aspx?mode=address\"\n",
    "    driver.get(base_url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.ID, \"btAgree\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    driver.find_element(By.ID, \"inpStreet\").send_keys(street_name)\n",
    "    driver.find_element(By.ID, \"btSearch\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Click the first result\n",
    "    try:\n",
    "        result_links = driver.find_elements(By.CSS_SELECTOR, \"#searchResults tr.SearchResults\")\n",
    "        if not result_links:\n",
    "            print(f\"[INFO] No results found for street: {street_name}\")\n",
    "            return\n",
    "        result_links[0].click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not click initial search result: {e}\")\n",
    "        return\n",
    "\n",
    "    total = get_total_record_count(driver)\n",
    "    print(f\"[INFO] Found {total} records for {street_name}\")\n",
    "\n",
    "    for i in range(total):\n",
    "        try:\n",
    "            click_tab(driver, \"Residential\")\n",
    "            data = scrape_residential_tab(driver)\n",
    "            \n",
    "\n",
    "            click_tab(driver, \"Photos\")\n",
    "            folder = os.path.join(output_dir, data.get(\"address\", f\"{street_name}_{i}\").replace(\" \", \"_\"))\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            scrape_and_download_photos_from_photoDetails(driver, folder)\n",
    "            \n",
    "            click_tab(driver, \"Sketch\")\n",
    "            sketch_data = scrape_sketch_details(driver)\n",
    "            scrape_sketch_image(driver, folder)\n",
    "\n",
    "            data[\"sketch_data\"] = sketch_data\n",
    "            \n",
    "            out_json = os.path.join(folder, \"data.json\")\n",
    "\n",
    "            with open(out_json, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "\n",
    "            print(f\"[SAVED] {data.get('address', 'Unknown')}\")\n",
    "\n",
    "            if i < total - 1:\n",
    "                driver.find_element(By.ID, \"DTLNavigator_imageNext\").click()\n",
    "                time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipped record {i} due to error: {e}\")\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:30:30.207868Z",
     "start_time": "2025-06-27T19:29:41.202405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "driver = init_driver(headless=False)\n",
    "driver.implicitly_wait(0)\n",
    "output_dir = \"scraped_properties\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "STREETS = [\"RAMBEAU RD\"]\n",
    "\n",
    "for street in STREETS:\n",
    "  scrape_all_records_on_street(driver, street, output_dir)\n",
    "\n",
    "driver.quit()"
   ],
   "id": "92786dcb708b8063",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 34 records for RAMBEAU RD\n",
      "[INFO] Saved current page HTML to debug_page.html\n",
      "[INFO] 8 rows found.\n",
      "[REMOVE ME] Data: {'Main Building': 900, 'A1 - 11:OFP OPEN FRAME PORCH': 270, 'A2 - 13:FR GR FRAME GARAGE': 576, 'A3 - 16:FROVR FRAME OVERHANG': 72, 'VINYL POOL - RP2:PREFABRICATED VINYL POOL': 512}\n",
      "[SAVED] Unknown\n",
      "[WARN] Tab with text 'Residential' not found.\n",
      "[WARN] Residential table not found.\n",
      "[WARN] Tab with text 'Photos' not found.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m STREETS = [\u001B[33m\"\u001B[39m\u001B[33mRAMBEAU RD\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m street \u001B[38;5;129;01min\u001B[39;00m STREETS:\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m   \u001B[43mscrape_all_records_on_street\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstreet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m driver.quit()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 184\u001B[39m, in \u001B[36mscrape_all_records_on_street\u001B[39m\u001B[34m(driver, street_name, output_dir)\u001B[39m\n\u001B[32m    182\u001B[39m folder = os.path.join(output_dir, data.get(\u001B[33m\"\u001B[39m\u001B[33maddress\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstreet_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m).replace(\u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m    183\u001B[39m os.makedirs(folder, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m184\u001B[39m \u001B[43mscrape_and_download_photos_from_photoDetails\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    186\u001B[39m click_tab(driver, \u001B[33m\"\u001B[39m\u001B[33mSketch\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    187\u001B[39m time.sleep(\u001B[32m10\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 56\u001B[39m, in \u001B[36mscrape_and_download_photos_from_photoDetails\u001B[39m\u001B[34m(driver, address_folder)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mscrape_and_download_photos_from_photoDetails\u001B[39m(driver, address_folder):\n\u001B[32m---> \u001B[39m\u001B[32m56\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait_for_photoDetails\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m     57\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m[WARN] photoDetails not found or empty.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     58\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m []\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 52\u001B[39m, in \u001B[36mwait_for_photoDetails\u001B[39m\u001B[34m(driver, timeout)\u001B[39m\n\u001B[32m     50\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m     51\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b99d37f3a2a6cb7e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
